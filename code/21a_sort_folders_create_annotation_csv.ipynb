{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code to sort the image files into a before and an after folder, remove unmatched before and after images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "IMG_DIR = os.path.join(DATA_DIR, 'images_ukraine_extracted')\n",
    "IMG_DIR_BEFORE = os.path.join(DATA_DIR, 'images_ukraine_extracted_before')\n",
    "IMG_DIR_AFTER = os.path.join(DATA_DIR, 'images_ukraine_extracted_after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32056/32056 [00:13<00:00, 2311.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# collect all event ids from image files\n",
    "img_dirs = os.listdir(IMG_DIR)\n",
    "\n",
    "# move all directories that end with \"after\" to \"images_ukraine_extracted_after\"\n",
    "after_dirs = [img_dir for img_dir in img_dirs if img_dir.endswith('after')]\n",
    "\n",
    "for img_dir in tqdm(after_dirs):\n",
    "    os.rename(os.path.join(IMG_DIR, img_dir), os.path.join(IMG_DIR + '_after', img_dir))\n",
    "\n",
    "# rename IMG_DIR to before\n",
    "os.rename(IMG_DIR, os.path.join(DATA_DIR, 'images_ukraine_extracted_before'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/174 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "img_dirs_before = os.listdir(IMG_DIR_BEFORE)\n",
    "image_event_ids_before = [img_dir.split('_')[-2] for img_dir in img_dirs_before]\n",
    "img_dirs_after =  os.listdir(IMG_DIR_AFTER)\n",
    "image_event_ids_after = [img_dir.split('_')[-2] for img_dir in img_dirs_after]\n",
    "\n",
    "# list all ids in before that are not in after\n",
    "ids_not_in_after = [event_id for event_id in image_event_ids_before if event_id not in image_event_ids_after]\n",
    "ids_not_in_before = [event_id for event_id in image_event_ids_after if event_id not in image_event_ids_before]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:01<00:00, 87.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# move unmatched directories to new directory\n",
    "for img_id in tqdm(ids_not_in_after):\n",
    "    # find img dir belonging to event id\n",
    "    img_dir = [img_dir for img_dir in img_dirs_before if img_dir.split(\"_\")[-2]==img_id][0]\n",
    "    os.rename(os.path.join(IMG_DIR_BEFORE, img_dir),\n",
    "              os.path.join(DATA_DIR, 'images_ukraine_unmatched', img_dir))\n",
    "    \n",
    "# now the same for after\n",
    "for img_id in tqdm(ids_not_in_before):\n",
    "    # find img dir belonging to event id\n",
    "    img_dir = [img_dir for img_dir in img_dirs_after if img_dir.split(\"_\")[-2]==img_id][0]\n",
    "    os.rename(os.path.join(IMG_DIR_AFTER, img_dir),\n",
    "              os.path.join(DATA_DIR, 'images_ukraine_unmatched', img_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now strip non-event id stuff from directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs_before = os.listdir(IMG_DIR_BEFORE)\n",
    "image_event_ids_before = [int(img_dir.split('_')[-2]) for img_dir in img_dirs_before]\n",
    "img_dirs_after =  os.listdir(IMG_DIR_AFTER)\n",
    "image_event_ids_after = [int(img_dir.split('_')[-2]) for img_dir in img_dirs_after]\n",
    "\n",
    "# strip img dirs of stuff that is not the event id\n",
    "for img_dir, event_id in tqdm(zip(img_dirs_before, image_event_ids_before)):\n",
    "    os.rename(os.path.join(IMG_DIR_BEFORE, img_dir),\n",
    "              os.path.join(IMG_DIR_BEFORE, f'{event_id}'))\n",
    "# now same for after\n",
    "for img_dir, event_id in tqdm(zip(img_dirs_after, image_event_ids_after)):\n",
    "    os.rename(os.path.join(IMG_DIR_AFTER, img_dir),\n",
    "              os.path.join(IMG_DIR_AFTER, f'{event_id}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97049/2183983191.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  event_df = pd.read_csv(os.path.join(DATA_DIR, 'ACLED_Ukraine_events_timeline.csv'))\n"
     ]
    }
   ],
   "source": [
    "event_df = pd.read_csv(os.path.join(DATA_DIR, 'ACLED_Ukraine_events_timeline.csv'))\n",
    "\n",
    "# keep only rows where timeline_id is in image_event_ids_before\n",
    "event_df_filtered = event_df[event_df['timeline_id'].isin(image_event_ids_before)]\n",
    "\n",
    "# keep only columns that are relevant\n",
    "event_df_filtered = event_df_filtered[['timeline_id', 'location_id', 'event_date', 'overlapping_event',\n",
    "                                       'event', 'any_event', 'cum_attack']]\n",
    "# save to csv\n",
    "event_df_filtered.to_csv(os.path.join(DATA_DIR, 'annotations_ukraine.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
