{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum batch size: 87\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Constants\n",
    "model_size = 1.3 * (1024 ** 2)  # Model size in bytes\n",
    "input_size_per_image = 22 * (1024 ** 2)  # Size of one image in bytes\n",
    "feature_size = 50 * (1024 ** 2)  # Size of features in bytes\n",
    "available_memory = 24 * (1024 ** 3)  # Available GPU memory in bytes\n",
    "\n",
    "# Estimate the overhead (2-3 times the model and input size)\n",
    "overhead_factor = 3\n",
    "\n",
    "# Finding maximum batch size\n",
    "max_batch_size = 1\n",
    "while True:\n",
    "    input_size = max_batch_size * (input_size_per_image * 2)  # For two images\n",
    "    features_size = max_batch_size * feature_size  # If applicable\n",
    "    total_memory = (model_size + input_size + features_size) * overhead_factor\n",
    "    \n",
    "    if total_memory > available_memory:\n",
    "        break\n",
    "    max_batch_size += 1\n",
    "\n",
    "print(f'Maximum batch size: {max_batch_size - 1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: 2024x2024\n",
      "Windows per dimension: 11x11 = 121 total windows\n",
      "\n",
      "Memory requirements:\n",
      "  Raw images: 93.76 MB\n",
      "  Feature map dictionary: 69.83 MB\n",
      "  Peak window batch: 18.38 MB\n",
      "  Final feature representation: 73.06 MB (both images)\n",
      "  Total processing memory: 236.66 MB\n",
      "  Total training memory: 709.98 MB (with gradients)\n",
      "\n",
      "Batch size calculations:\n",
      "  Model size: 1331.20 MB\n",
      "  Available GPU memory: 24576.00 MB\n",
      "  Maximum batch size: 32\n",
      "  Effective batch size with gradient accumulation: 128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model constants\n",
    "model_size_mb = 1.3 * 1024  # ViT-B MAE model size in MB\n",
    "feature_dim = 768  # ViT-B feature dimension \n",
    "window_size = 224\n",
    "overlap = 56\n",
    "patch_size = 16\n",
    "\n",
    "# Image parameters (typical satellite image)\n",
    "img_height = 2024 \n",
    "img_width = 2024\n",
    "img_channels = 3\n",
    "\n",
    "# Calculate windows per image\n",
    "stride = window_size - overlap\n",
    "windows_h = max(1, (img_height - window_size) // stride + 1)\n",
    "windows_w = max(1, (img_width - window_size) // stride + 1)\n",
    "total_windows = windows_h * windows_w\n",
    "\n",
    "print(f\"Image dimensions: {img_height}x{img_width}\")\n",
    "print(f\"Windows per dimension: {windows_h}x{windows_w} = {total_windows} total windows\")\n",
    "\n",
    "# Image memory requirements\n",
    "image_size_mb = 2 * img_height * img_width * img_channels * 4 / (1024*1024)  # Two images (before/after), 4 bytes per float\n",
    "\n",
    "# Window processing (peak during feature extraction)\n",
    "inference_window_batch_size = 32  # Adjust based on implementation\n",
    "peak_window_batch_mb = window_size * window_size * img_channels * 4 * inference_window_batch_size / (1024*1024)\n",
    "\n",
    "# Feature extraction memory\n",
    "feature_tokens_per_window = (window_size // patch_size) ** 2 + 1  # +1 for CLS token\n",
    "feature_size_per_window_mb = feature_tokens_per_window * feature_dim * 4 / (1024*1024)  # 4 bytes per float\n",
    "feature_map_mb = feature_size_per_window_mb * total_windows  # Dictionary of all window features\n",
    "\n",
    "# Final merged feature representation (only active tokens in circle)\n",
    "feature_grid_h = img_height // patch_size\n",
    "feature_grid_w = img_width // patch_size\n",
    "total_grid_size = feature_grid_h * feature_grid_w\n",
    "circle_ratio = 3.14159 / 4  # π/4 (ratio of circle to square)\n",
    "active_tokens = int(total_grid_size * circle_ratio) + 1  # +1 for CLS\n",
    "final_feature_mb = active_tokens * feature_dim * 4 / (1024*1024)\n",
    "\n",
    "# Total memory per sample (accounting for both before/after images)\n",
    "# During processing we need: raw images + peak of either window batch or feature map + final representation\n",
    "processing_memory_mb = image_size_mb + max(peak_window_batch_mb, feature_map_mb) + 2 * final_feature_mb\n",
    "\n",
    "# Training specific memory (gradients, optimizer states)\n",
    "training_overhead_factor = 3  # Higher for training due to gradients\n",
    "training_memory_mb = processing_memory_mb * training_overhead_factor\n",
    "\n",
    "# Calculate max batch size based on available GPU memory\n",
    "available_memory_mb = 24 * 1024  # 24 GB GPU\n",
    "max_batch_size = max(1, int((available_memory_mb - model_size_mb) / training_memory_mb))\n",
    "\n",
    "# Consider gradient accumulation\n",
    "gradient_accumulation_steps = 4\n",
    "effective_batch_size = max_batch_size * gradient_accumulation_steps\n",
    "\n",
    "print(f\"\\nMemory requirements:\")\n",
    "print(f\"  Raw images: {image_size_mb:.2f} MB\")\n",
    "print(f\"  Feature map dictionary: {feature_map_mb:.2f} MB\")\n",
    "print(f\"  Peak window batch: {peak_window_batch_mb:.2f} MB\")\n",
    "print(f\"  Final feature representation: {2 * final_feature_mb:.2f} MB (both images)\")\n",
    "print(f\"  Total processing memory: {processing_memory_mb:.2f} MB\")\n",
    "print(f\"  Total training memory: {training_memory_mb:.2f} MB (with gradients)\")\n",
    "print(f\"\\nBatch size calculations:\")\n",
    "print(f\"  Model size: {model_size_mb:.2f} MB\")\n",
    "print(f\"  Available GPU memory: {available_memory_mb:.2f} MB\")\n",
    "print(f\"  Maximum batch size: {max_batch_size}\")\n",
    "print(f\"  Effective batch size with gradient accumulation: {effective_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838.986328125"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15876"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H=2017\n",
    "W=2028\n",
    "window_size=16\n",
    "window_n1 = 0\n",
    "h_center, w_center = H/2, W/2\n",
    "\n",
    "for h in range(0, H - window_size + 1, window_size):\n",
    "        for w in range(0, W - window_size + 1, window_size):\n",
    "            window_n1 += 1\n",
    "window_n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12713"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate circle parameters\n",
    "H=2017\n",
    "W=2028\n",
    "window_size=16\n",
    "window_n2 = 0\n",
    "h_center, w_center = H/2, W/2\n",
    "radius = min(H, W)/2 - 1  # Slightly smaller than half the image dimension\n",
    "\n",
    "# Create batches of windows, but only include windows that intersect with the circle\n",
    "for h in range(0, H - window_size + 1, window_size):\n",
    "    for w in range(0, W - window_size + 1, window_size):\n",
    "        # Calculate window center\n",
    "        window_center_h = h + window_size/2\n",
    "        window_center_w = w + window_size/2\n",
    "        \n",
    "        # Calculate distance from window center to image center\n",
    "        dist_to_center = ((window_center_h - h_center)**2 + (window_center_w - w_center)**2)**0.5\n",
    "        \n",
    "        # Only process windows that are at least partially within the circle\n",
    "        window_radius = window_size/2 * 1.414  # Diagonal radius of window (√2 × half_size)\n",
    "        if dist_to_center <= radius + window_radius:\n",
    "            window_n2 += 1\n",
    "window_n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8007684555303602"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_n2/window_n1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
