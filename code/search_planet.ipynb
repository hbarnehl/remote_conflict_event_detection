{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "import getpass\n",
    "from planet import Auth, Session\n",
    "import json\n",
    "from planet_helpers import set_filters, parse_polygon\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "DOWNLOAD_DIR = '../data/planet_data'\n",
    "FILTER_DIR = '../data/filters'\n",
    "SEARCH_DIR = '../data/searches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = input(\"Username: \")\n",
    "pw = getpass.getpass()\n",
    "auth = Auth.from_login(user,pw)\n",
    "auth.store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv('../data/ACLED_Ukraine_events_sample.csv')[['location_id', 'event_date', 'event_id_cnty', 'timeline_id']]\n",
    "non_events = pd.read_csv('../data/ACLED_Ukraine_non_events_sample.csv')[['location_id', 'event_date', 'timeline_id']]\n",
    "\n",
    "places = pd.read_csv(\"../data/places.csv\")\n",
    "\n",
    "# merge events with places on location_id\n",
    "events = events.merge(places, on='location_id')\n",
    "non_events = non_events.merge(places, on='location_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filters = []\n",
    "\n",
    "for event in tqdm(non_events.iterrows(), total=len(non_events)):\n",
    "   \n",
    "   coords = parse_polygon(event[1]['geometry'])\n",
    "   \n",
    "   geom = {\n",
    "         \"type\": \"Polygon\",\n",
    "         \"coordinates\": coords\n",
    "      }\n",
    "\n",
    "   date = datetime.strptime(event[1][\"event_date\"], \"%Y-%m-%d\")\n",
    "   # subtract 5 days from the event date\n",
    "   five_before = (date - pd.DateOffset(days=5)).to_pydatetime()\n",
    "   five_after = (date + pd.DateOffset(days=5)).to_pydatetime()\n",
    "\n",
    "   filters = set_filters(from_date=five_before, to_date = five_after, geom=geom)\n",
    "   all_filters.append(filters)\n",
    "\n",
    "# save filters\n",
    "with open(FILTER_DIR + '/filters_non_events.jsonl', 'w') as file:\n",
    "    for entry in all_filters:\n",
    "        # Convert each dictionary to a JSON string and write it to the file\n",
    "        file.write(json.dumps(entry) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the filter to searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type = 'non_events'\n",
    "df = pd.read_csv('../data/ACLED_Ukraine_' + event_type + '_sample.csv')\n",
    "\n",
    "async with Session() as sess:\n",
    "    cl = sess.client('data')\n",
    "\n",
    "    with open(FILTER_DIR + '/filters_' + event_type + '.jsonl', 'r') as file:\n",
    "        # Initialize tqdm with manual update\n",
    "        pbar = tqdm(total=len(df))\n",
    "        \n",
    "        for i, line in enumerate(file):\n",
    "            timeline_id = str(df['timeline_id'][i])\n",
    "            name = event_type + '_' + timeline_id\n",
    "            JSON_DIR = SEARCH_DIR + '/' + name + '.json'\n",
    "\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Check if file already exists\n",
    "            if os.path.exists(JSON_DIR):\n",
    "                # print(f\"Search {name} already exists\")\n",
    "                continue\n",
    "            else:\n",
    "                # print(f\"Creating search {name}\")\n",
    "                filters = json.loads(line)\n",
    "                \n",
    "                request = await cl.create_search(name=name,\n",
    "                                                 search_filter=filters,\n",
    "                                                 item_types=[\"PSScene\"])\n",
    "                with open(JSON_DIR, 'w') as f:\n",
    "                    f.write(json.dumps(request))\n",
    "        \n",
    "        # Close the progress bar\n",
    "        pbar.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
